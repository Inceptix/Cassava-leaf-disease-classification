{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input\n",
    "from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "import tensorflow_addons as tfa\n",
    "import albumentations as A\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "#from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla V100-SXM2-16GB, compute capability 7.0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "seed(seed_value)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cassava_Production_Notebook.ipynb\t  'effnetb4 3fold.h5'\r\n",
      " cassava-leaf-disease-classification.zip  'effnetb4 4fold.h5'\r\n",
      " data\t\t\t\t\t  'effnetb4 5fold.h5'\r\n",
      "'denoised effnetb4 1fold.h5'\t\t   nohup.out\r\n",
      "'effnetb0 1fold.h5'\t\t\t   pytorch-and-tf-with-jupyter.def\r\n",
      "'effnetb0 2fold.h5'\t\t\t   pytorch_21.03-py3.sif\r\n",
      "'effnetb0 3fold.h5'\t\t\t   tensorflow-with-jupyter.def\r\n",
      "'effnetb0 4fold.h5'\t\t\t   tensorflow-with-jupyter.sif\r\n",
      "'effnetb0 5fold.h5'\t\t\t   tensorflow_21.02-tf2-py3.sif\r\n",
      "'effnetb4 1fold.h5'\t\t\t   tensorflow_21.03-tf2-py3.sif\r\n",
      "'effnetb4 2fold.h5'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5409\r\n",
      "drwxr-xr-x  6 tug98850 cis      9 Mar 23 19:36 .\r\n",
      "drwx------ 14 tug98850 cis     40 Apr  2 00:02 ..\r\n",
      "-rw-r--r--  1 tug98850 cis    172 Nov 25 16:35 label_num_to_disease_map.json\r\n",
      "-rw-r--r--  1 tug98850 cis     32 Nov 25 16:35 sample_submission.csv\r\n",
      "drwxr-xr-x  2 tug98850 cis      3 Mar 23 19:33 test_images\r\n",
      "drwxr-xr-x  2 tug98850 cis      3 Mar 23 19:33 test_tfrecords\r\n",
      "-rw-r--r--  1 tug98850 cis 358283 Nov 25 16:35 train.csv\r\n",
      "drwxr-xr-x  2 tug98850 cis  21399 Mar 23 19:33 train_images\r\n",
      "drwxr-xr-x  2 tug98850 cis     18 Mar 23 19:34 train_tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/train_images/1000015157.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>./data/train_images/1000201771.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/train_images/100042118.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/train_images/1000723321.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>./data/train_images/1000812911.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label                            filepath\n",
       "0  1000015157.jpg      0  ./data/train_images/1000015157.jpg\n",
       "1  1000201771.jpg      3  ./data/train_images/1000201771.jpg\n",
       "2   100042118.jpg      1   ./data/train_images/100042118.jpg\n",
       "3  1000723321.jpg      1  ./data/train_images/1000723321.jpg\n",
       "4  1000812911.jpg      3  ./data/train_images/1000812911.jpg"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "training_folder = './data/train_images/'\n",
    "df_train[\"filepath\"] = training_folder + df_train[\"image_id\"]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# original image_size = 224\n",
    "image_size = 380\n",
    "input_shape = (image_size, image_size, 3)\n",
    "epochs = 15\n",
    "CLASSES = ['0', '1', '2', '3', '4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed_value)\n",
    "for train_index, val_index in skf.split(df_train[\"image_id\"], df_train[\"label\"]):\n",
    "    train_data = df_train.loc[train_index]\n",
    "    val_data = df_train.loc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_label_from_path(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 17117 \t number of validation images: 4280\n"
     ]
    }
   ],
   "source": [
    "training_data = tf.data.Dataset.from_tensor_slices((train_data[\"filepath\"].values, train_data[\"label\"].values))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((val_data[\"filepath\"].values, val_data[\"label\"].values))\n",
    "\n",
    "training_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "validation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "\n",
    "print(\"number of training images: {ti} \\t number of validation images: {vi}\".format(ti=len(training_data), vi=len(validation_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "Map the image augmentations to the tf tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_data(train_ds):\n",
    "    transforms = A.Compose([\n",
    "            A.RandomResizedCrop(image_size, image_size),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            A.CoarseDropout(p=0.5),\n",
    "            A.Cutout(p=0.5),\n",
    "            ], p=1)\n",
    "    \n",
    "    def aug_fn(image):\n",
    "        data = {\"image\":image}\n",
    "        aug_data = transforms(**data)\n",
    "        aug_img = aug_data[\"image\"]\n",
    "        aug_img = tf.cast(aug_img, tf.float32)\n",
    "        return aug_img\n",
    "\n",
    "    def process_data(image, label):\n",
    "        aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "        return aug_img, label\n",
    "    \n",
    "    def set_shapes(img, label, img_shape=(image_size,image_size,3)):\n",
    "        img.set_shape(img_shape)\n",
    "        label.set_shape([])\n",
    "        return img, label\n",
    "    \n",
    "    ds_alb = train_ds.map(partial(process_data), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    ds_alb = ds_alb.map(set_shapes, num_parallel_calls=AUTOTUNE)\n",
    "    ds_alb = ds_alb.repeat()\n",
    "    ds_alb = ds_alb.batch(batch_size)\n",
    "    return ds_alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_val_data(val_ds):\n",
    "    transforms = A.Compose([\n",
    "                A.CenterCrop(image_size, image_size),\n",
    "                ], p=1)\n",
    "    \n",
    "    def aug_fn(image):\n",
    "        data = {\"image\":image}\n",
    "        aug_data = transforms(**data)\n",
    "        aug_img = aug_data[\"image\"]\n",
    "        aug_img = tf.cast(aug_img, tf.float32)\n",
    "        return aug_img\n",
    "\n",
    "    def process_data(image, label):\n",
    "        aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "        return aug_img, label\n",
    "    \n",
    "    def set_shapes(img, label, img_shape=(image_size, image_size,3)):\n",
    "        img.set_shape(img_shape)\n",
    "        label.set_shape([])\n",
    "        return img, label\n",
    "    \n",
    "    ds_alb = val_ds.map(partial(process_data), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "    ds_alb = ds_alb.map(set_shapes, num_parallel_calls=AUTOTUNE).batch(batch_size)\n",
    "    return ds_alb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model and Training\n",
    "Create and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #Creating the model\n",
    "  \n",
    "    #preproccess to resize to 224, because it's what B0 calls for\n",
    "    #img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.efficientnet.preprocess_input, input_shape=input_shape)\n",
    "\n",
    "    # customized model\n",
    "    #base_model = efn.EfficientNetB6(weights='noisy-student',\n",
    "                                    #include_top=False)\n",
    "    \n",
    "\n",
    "    base_model = efn.EfficientNetB4(weights='noisy-student',\n",
    "                                    include_top=False,\n",
    "                                    input_shape=input_shape)\n",
    "    \n",
    "    #rebuild top\n",
    "    inputs = Input(shape=input_shape)\n",
    "    built_model = base_model(inputs)\n",
    "    pooling = GlobalAveragePooling2D()(built_model)\n",
    "    dropout=Dropout(0.3)(pooling)\n",
    "    dense=Dense(8, activation='relu')(dropout)\n",
    "    outputs=Dense(5, activation='softmax', dtype='float32')(dense)\n",
    "\n",
    "    #compile\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    #learning rate scheduler\n",
    "    # adjust this based on steps\n",
    "    lr_scheduler = keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=1e-3,\n",
    "        decay_steps=(int(len(df_train)*0.04/batch_size)+1)*epochs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01),  \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(train_data, val_data):\n",
    "    training_data = tf.data.Dataset.from_tensor_slices((train_data[\"filepath\"].values, train_data[\"label\"].values))\n",
    "    validation_data = tf.data.Dataset.from_tensor_slices((val_data[\"filepath\"].values, val_data[\"label\"].values))\n",
    "\n",
    "    training_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "    validation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    return (training_data, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "# try adjusting this\n",
    "total_steps = (int(len(df_train)*0.08/batch_size)+1)\n",
    "#total_steps = len(training_data) // batch_size\n",
    "#DON'T FORGET TO RESET FOLD NUMBER TO 0\n",
    "fold_number = 0\n",
    "n_splits = 5\n",
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n",
    "for train_index, val_index in skf.split(df_train[\"image_id\"], df_train[\"label\"]):\n",
    "    train_list.append(train_index)\n",
    "    val_list.append(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for optimization\n",
    "def onehot(image,label):\n",
    "    CLASSES = 5\n",
    "    return image,tf.one_hot(label,CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model and Training\n",
    "Create and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 1\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 138s 586ms/step - loss: 1.3024 - accuracy: 0.5216 - val_loss: 1.0934 - val_accuracy: 0.5771\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.8500 - accuracy: 0.6769 - val_loss: 0.6824 - val_accuracy: 0.7582\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 43s 407ms/step - loss: 0.8064 - accuracy: 0.7344 - val_loss: 0.7630 - val_accuracy: 0.7556\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 43s 402ms/step - loss: 0.7065 - accuracy: 0.7603 - val_loss: 0.6290 - val_accuracy: 0.8023\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.6790 - accuracy: 0.7768 - val_loss: 0.6537 - val_accuracy: 0.7876\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 41s 386ms/step - loss: 0.5869 - accuracy: 0.8064 - val_loss: 0.5426 - val_accuracy: 0.8264\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 38s 356ms/step - loss: 0.6176 - accuracy: 0.7865 - val_loss: 0.5249 - val_accuracy: 0.8292\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.5799 - accuracy: 0.8068 - val_loss: 0.4638 - val_accuracy: 0.8607\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 39s 366ms/step - loss: 0.5978 - accuracy: 0.8096 - val_loss: 0.4506 - val_accuracy: 0.8643\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 38s 359ms/step - loss: 0.5393 - accuracy: 0.8271 - val_loss: 0.4515 - val_accuracy: 0.8650\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.5148 - accuracy: 0.8302 - val_loss: 0.4508 - val_accuracy: 0.8659\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 40s 371ms/step - loss: 0.5106 - accuracy: 0.8268 - val_loss: 0.4492 - val_accuracy: 0.8645\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 39s 371ms/step - loss: 0.5494 - accuracy: 0.8256 - val_loss: 0.4501 - val_accuracy: 0.8645\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 39s 364ms/step - loss: 0.5382 - accuracy: 0.8315 - val_loss: 0.4518 - val_accuracy: 0.8657\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 38s 354ms/step - loss: 0.5368 - accuracy: 0.8211 - val_loss: 0.4522 - val_accuracy: 0.8633\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 40s 377ms/step - loss: 0.5451 - accuracy: 0.8154 - val_loss: 0.4520 - val_accuracy: 0.8659\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 43s 404ms/step - loss: 0.5497 - accuracy: 0.8207 - val_loss: 0.4495 - val_accuracy: 0.8657\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 2\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 79s 443ms/step - loss: 1.2504 - accuracy: 0.5360 - val_loss: 1.1995 - val_accuracy: 0.5442\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.8871 - accuracy: 0.6842 - val_loss: 0.8620 - val_accuracy: 0.7353\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 42s 392ms/step - loss: 0.8174 - accuracy: 0.7063 - val_loss: 0.7491 - val_accuracy: 0.7498\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 44s 408ms/step - loss: 0.8002 - accuracy: 0.7224 - val_loss: 0.6119 - val_accuracy: 0.7827\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.6940 - accuracy: 0.7563 - val_loss: 0.6878 - val_accuracy: 0.7423\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 39s 370ms/step - loss: 0.6448 - accuracy: 0.7821 - val_loss: 0.5391 - val_accuracy: 0.8208\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 40s 376ms/step - loss: 0.6685 - accuracy: 0.7661 - val_loss: 0.4867 - val_accuracy: 0.8460\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 40s 377ms/step - loss: 0.6164 - accuracy: 0.8059 - val_loss: 0.4848 - val_accuracy: 0.8484\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 45s 426ms/step - loss: 0.6165 - accuracy: 0.7766 - val_loss: 0.4584 - val_accuracy: 0.8619\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.6060 - accuracy: 0.8025 - val_loss: 0.4553 - val_accuracy: 0.8614\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 44s 410ms/step - loss: 0.5631 - accuracy: 0.8144 - val_loss: 0.4546 - val_accuracy: 0.8629\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 43s 408ms/step - loss: 0.5397 - accuracy: 0.8241 - val_loss: 0.4546 - val_accuracy: 0.8633\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 44s 416ms/step - loss: 0.5818 - accuracy: 0.8138 - val_loss: 0.4556 - val_accuracy: 0.8624\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.6160 - accuracy: 0.8127 - val_loss: 0.4557 - val_accuracy: 0.8631\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.5452 - accuracy: 0.8186 - val_loss: 0.4564 - val_accuracy: 0.8617\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 45s 424ms/step - loss: 0.5405 - accuracy: 0.8328 - val_loss: 0.4555 - val_accuracy: 0.8638\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.5740 - accuracy: 0.8098 - val_loss: 0.4551 - val_accuracy: 0.8638\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 3\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 86s 512ms/step - loss: 1.2505 - accuracy: 0.5182 - val_loss: 1.3986 - val_accuracy: 0.3856\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 45s 419ms/step - loss: 0.8928 - accuracy: 0.6656 - val_loss: 0.8015 - val_accuracy: 0.7137\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 45s 426ms/step - loss: 0.8133 - accuracy: 0.7220 - val_loss: 0.7758 - val_accuracy: 0.7560\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 48s 448ms/step - loss: 0.7958 - accuracy: 0.7287 - val_loss: 0.6422 - val_accuracy: 0.7929\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.6562 - accuracy: 0.7799 - val_loss: 0.5954 - val_accuracy: 0.8126\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 0.6829 - accuracy: 0.7763 - val_loss: 0.6127 - val_accuracy: 0.8088\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.6402 - accuracy: 0.7810 - val_loss: 0.5767 - val_accuracy: 0.8194\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 46s 435ms/step - loss: 0.6012 - accuracy: 0.8111 - val_loss: 0.5260 - val_accuracy: 0.8446\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 46s 427ms/step - loss: 0.5937 - accuracy: 0.8083 - val_loss: 0.5255 - val_accuracy: 0.8476\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 46s 432ms/step - loss: 0.5924 - accuracy: 0.7983 - val_loss: 0.5289 - val_accuracy: 0.8446\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 43s 402ms/step - loss: 0.5998 - accuracy: 0.7956 - val_loss: 0.5261 - val_accuracy: 0.8458\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 43s 407ms/step - loss: 0.5428 - accuracy: 0.8228 - val_loss: 0.5248 - val_accuracy: 0.8462\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 44s 410ms/step - loss: 0.6073 - accuracy: 0.8031 - val_loss: 0.5240 - val_accuracy: 0.8465\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.5989 - accuracy: 0.8163 - val_loss: 0.5265 - val_accuracy: 0.8441\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 43s 402ms/step - loss: 0.5855 - accuracy: 0.8157 - val_loss: 0.5260 - val_accuracy: 0.8448\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 42s 395ms/step - loss: 0.6061 - accuracy: 0.7968 - val_loss: 0.5271 - val_accuracy: 0.8458\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 42s 399ms/step - loss: 0.6006 - accuracy: 0.8089 - val_loss: 0.5246 - val_accuracy: 0.8467\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 43s 400ms/step - loss: 0.5857 - accuracy: 0.8030 - val_loss: 0.5262 - val_accuracy: 0.8462\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 4\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 80s 448ms/step - loss: 1.2642 - accuracy: 0.5401 - val_loss: 1.0678 - val_accuracy: 0.5976\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 42s 393ms/step - loss: 0.8667 - accuracy: 0.6799 - val_loss: 0.7987 - val_accuracy: 0.7266\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.7687 - accuracy: 0.7251 - val_loss: 0.9965 - val_accuracy: 0.7104\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 42s 392ms/step - loss: 0.7101 - accuracy: 0.7662 - val_loss: 0.5937 - val_accuracy: 0.8079\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 40s 372ms/step - loss: 0.6582 - accuracy: 0.7761 - val_loss: 0.6306 - val_accuracy: 0.7943\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 40s 378ms/step - loss: 0.6482 - accuracy: 0.7781 - val_loss: 0.5070 - val_accuracy: 0.8399\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 40s 380ms/step - loss: 0.6353 - accuracy: 0.7844 - val_loss: 0.4994 - val_accuracy: 0.8425\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.5603 - accuracy: 0.8092 - val_loss: 0.4747 - val_accuracy: 0.8486\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.5416 - accuracy: 0.8342 - val_loss: 0.4650 - val_accuracy: 0.8546\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.5044 - accuracy: 0.8398 - val_loss: 0.4629 - val_accuracy: 0.8537\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 43s 405ms/step - loss: 0.5230 - accuracy: 0.8323 - val_loss: 0.4612 - val_accuracy: 0.8553\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 45s 418ms/step - loss: 0.5509 - accuracy: 0.8065 - val_loss: 0.4600 - val_accuracy: 0.8570\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.5617 - accuracy: 0.8122 - val_loss: 0.4601 - val_accuracy: 0.8574\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.5192 - accuracy: 0.8459 - val_loss: 0.4607 - val_accuracy: 0.8565\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.5006 - accuracy: 0.8285 - val_loss: 0.4627 - val_accuracy: 0.8551\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 43s 399ms/step - loss: 0.5320 - accuracy: 0.8299 - val_loss: 0.4624 - val_accuracy: 0.8551\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 42s 394ms/step - loss: 0.5641 - accuracy: 0.8017 - val_loss: 0.4590 - val_accuracy: 0.8584\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.5354 - accuracy: 0.8307 - val_loss: 0.4599 - val_accuracy: 0.8563\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 44s 410ms/step - loss: 0.5321 - accuracy: 0.8303 - val_loss: 0.4618 - val_accuracy: 0.8542\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.5031 - accuracy: 0.8288 - val_loss: 0.4620 - val_accuracy: 0.8535\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 5\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 80s 449ms/step - loss: 1.2597 - accuracy: 0.5079 - val_loss: 1.1010 - val_accuracy: 0.5532\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 43s 401ms/step - loss: 0.8955 - accuracy: 0.6688 - val_loss: 0.7354 - val_accuracy: 0.7401\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 43s 402ms/step - loss: 0.7904 - accuracy: 0.7342 - val_loss: 0.6945 - val_accuracy: 0.7815\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 44s 408ms/step - loss: 0.6970 - accuracy: 0.7773 - val_loss: 0.5816 - val_accuracy: 0.8163\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 43s 405ms/step - loss: 0.7218 - accuracy: 0.7482 - val_loss: 0.5980 - val_accuracy: 0.8025\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 41s 388ms/step - loss: 0.6386 - accuracy: 0.7881 - val_loss: 0.5083 - val_accuracy: 0.8425\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 41s 382ms/step - loss: 0.6422 - accuracy: 0.7970 - val_loss: 0.4683 - val_accuracy: 0.8516\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.5522 - accuracy: 0.8245 - val_loss: 0.4627 - val_accuracy: 0.8509\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 45s 418ms/step - loss: 0.5803 - accuracy: 0.8077 - val_loss: 0.4558 - val_accuracy: 0.8521\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 42s 392ms/step - loss: 0.5962 - accuracy: 0.7963 - val_loss: 0.4500 - val_accuracy: 0.8567\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.5606 - accuracy: 0.8246 - val_loss: 0.4496 - val_accuracy: 0.8565\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 41s 381ms/step - loss: 0.5132 - accuracy: 0.8287 - val_loss: 0.4477 - val_accuracy: 0.8563\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 43s 405ms/step - loss: 0.5732 - accuracy: 0.8123 - val_loss: 0.4470 - val_accuracy: 0.8574\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 0.5481 - accuracy: 0.8250 - val_loss: 0.4475 - val_accuracy: 0.8579\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.5431 - accuracy: 0.8349 - val_loss: 0.4488 - val_accuracy: 0.8574\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 44s 414ms/step - loss: 0.5198 - accuracy: 0.8331 - val_loss: 0.4508 - val_accuracy: 0.8553\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.5895 - accuracy: 0.7928 - val_loss: 0.4465 - val_accuracy: 0.8567\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 43s 407ms/step - loss: 0.5192 - accuracy: 0.8342 - val_loss: 0.4485 - val_accuracy: 0.8558\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 46s 427ms/step - loss: 0.5298 - accuracy: 0.8308 - val_loss: 0.4508 - val_accuracy: 0.8556\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 42s 395ms/step - loss: 0.5607 - accuracy: 0.8168 - val_loss: 0.4490 - val_accuracy: 0.8572\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "oof_accuracy = []\n",
    "\n",
    "for i in range(n_splits-fold_number): \n",
    "    # clearing memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # data split\n",
    "    train_set = df_train.loc[train_list[fold_number]]\n",
    "    val_set = df_train.loc[val_list[fold_number]]\n",
    "    \n",
    "    train_data, val_data_ = train_val_split(train_set, val_set)\n",
    "    \n",
    "    train_alb = augment_train_data(train_data)\n",
    "    val_alb = augment_val_data(val_data_)\n",
    "    \n",
    "    #train_final, val_final = optimize_data(train_alb, val_alb)\n",
    "    \n",
    "    train_alb_mod = train_alb.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    train_final = train_alb_mod.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    val_alb_mod = val_alb.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    val_final = val_alb_mod.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    # create the model\n",
    "    model = create_model()\n",
    "    \n",
    "    print(\"Training fold no.: \" + str(fold_number+1))\n",
    "\n",
    "    model_name = \"effnetb4 \"\n",
    "    fold_name = \"fold.h5\"\n",
    "    filepath = model_name + str(fold_number+1) + fold_name\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
    "                 ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True)]\n",
    "\n",
    "    # train\n",
    "    history = model.fit(train_final, steps_per_epoch=total_steps, epochs=epochs, validation_data=val_final, callbacks=callbacks)\n",
    "    oof_accuracy.append(max(history.history[\"val_accuracy\"]))\n",
    "    fold_number += 1\n",
    "    if fold_number == n_splits:\n",
    "        print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Out-Of-Fold Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Out-Of-Fold Accuracy: {:.2f}\".format(np.mean(oof_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load our models\n",
    "models = [] \n",
    "for i in range(5):\n",
    "    effnet = load_model(\"./effnetb4 \" + str(i+1) + \"fold.h5\")\n",
    "    models.append(effnet)\n",
    "\n",
    "model_one = models[0]\n",
    "model_two = models[1]\n",
    "model_three = models[2]\n",
    "model_four = models[3]\n",
    "model_five = models[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we get our validation data\n",
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "val_list = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, val_index in skf.split(df[\"image_id\"], df[\"label\"]):\n",
    "    val_list.append(val_index)\n",
    "\n",
    "one_fold = df.loc[val_list[0]]\n",
    "two_fold = df.loc[val_list[1]]\n",
    "three_fold = df.loc[val_list[2]]\n",
    "four_fold = df.loc[val_list[3]]\n",
    "five_fold = df.loc[val_list[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(0.2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_image(img_path, image_size=image_size, tta_runs=2):\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((image_size, image_size))\n",
    "    img_height, img_width = img.size\n",
    "    img = np.array(img)\n",
    "    \n",
    "    img_list = []\n",
    "    for i in range(tta_runs):\n",
    "        img_list.append(img)\n",
    "  \n",
    "    return np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_tta(image_filename, folder, tta_runs=2):\n",
    "    \n",
    "    #apply TTA to each of the 3 images and sum all predictions for each local image\n",
    "    localised_predictions = []\n",
    "    local_image_list = duplicate_image(folder+image_filename)\n",
    "    for local_image in local_image_list:\n",
    "        local_image = tf.expand_dims(local_image,0)\n",
    "        augmented_images = [tta(local_image) for i in range(tta_runs)]\n",
    "        predictions = model.predict(np.array(augmented_images[0]))\n",
    "        localised_predictions.append(np.sum(predictions, axis=0))\n",
    "    \n",
    "    #sum all predictions from all 3 images and retrieve the index of the highest value\n",
    "    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n",
    "    max_value = max(global_predictions)\n",
    "    final_prediction = np.argmax(global_predictions)\n",
    "    \n",
    "    return [final_prediction, max_value, global_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  4\n",
      "Predicted Label Value:  0.7359253\n",
      "Predicted One-Hot Label:  [0.6148509  0.49956995 0.11468517 0.03496872 0.7359253 ]\n"
     ]
    }
   ],
   "source": [
    "train_folder = \"./data/train_images/\"\n",
    "train_image = \"1000015157.jpg\"\n",
    "predictions = predict_with_tta(train_image, train_folder)\n",
    "\n",
    "print(\"Predicted Label: \", predictions[0])\n",
    "print(\"Predicted Label Value: \", predictions[1])\n",
    "print(\"Predicted One-Hot Label: \", predictions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Level: 36.80 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Confidence Level: {:.2f}\".format(predictions[1]/2*100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Out-Of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_list(image_list, folder):\n",
    "    predictions = []\n",
    "    values = []\n",
    "    with tqdm(total=len(image_list)) as pbar:\n",
    "        for image_filename in image_list:\n",
    "            pbar.update(1)\n",
    "            predictions.append(predict_with_tta(image_filename, folder)[0])\n",
    "            values.append(predict_with_tta(image_filename, folder)[1])\n",
    "    return [predictions, values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4280/4280 [36:37<00:00,  1.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.191875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.900006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.722907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.088217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.959418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  pred     value\n",
       "0  1000015157.jpg      0     4  1.191875\n",
       "1  1000201771.jpg      3     3  1.900006\n",
       "2   100042118.jpg      1     4  1.722907\n",
       "3  1000723321.jpg      1     1  1.088217\n",
       "4  1000812911.jpg      3     3  1.959418"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_one\n",
    "placeholder = predict_image_list(one_fold[\"image_id\"], train_folder)\n",
    "one_fold[\"pred\"] = placeholder[0]\n",
    "one_fold[\"value\"] = placeholder[1]\n",
    "one_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4280/4280 [36:59<00:00,  1.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>1741376467.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.718303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>1742921296.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.378709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>1744132907.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.736743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>1745213235.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.892229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>1748078047.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.863447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  label  pred     value\n",
       "4152  1741376467.jpg      2     2  1.718303\n",
       "4160  1742921296.jpg      2     3  1.378709\n",
       "4165  1744132907.jpg      2     2  1.736743\n",
       "4170  1745213235.jpg      2     2  1.892229\n",
       "4186  1748078047.jpg      2     2  0.863447"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_two\n",
    "placeholder = predict_image_list(two_fold[\"image_id\"], train_folder)\n",
    "two_fold[\"pred\"] = placeholder[0]\n",
    "two_fold[\"value\"] = placeholder[1]\n",
    "two_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4279/4279 [38:11<00:00,  1.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8381</th>\n",
       "      <td>248855703.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.916682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8384</th>\n",
       "      <td>2488945331.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.969591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8403</th>\n",
       "      <td>2491752039.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.657983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8407</th>\n",
       "      <td>2492550594.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.334445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>2494764703.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.972245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  label  pred     value\n",
       "8381   248855703.jpg      2     2  1.916682\n",
       "8384  2488945331.jpg      2     2  1.969591\n",
       "8403  2491752039.jpg      2     2  1.657983\n",
       "8407  2492550594.jpg      2     2  1.334445\n",
       "8416  2494764703.jpg      2     2  1.972245"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_three\n",
    "placeholder = predict_image_list(three_fold[\"image_id\"], train_folder)\n",
    "three_fold[\"pred\"] = placeholder[0]\n",
    "three_fold[\"value\"] = placeholder[1]\n",
    "three_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4279/4279 [38:13<00:00,  1.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>3290333742.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.248505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>3292343702.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.777464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12801</th>\n",
       "      <td>3293012629.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.916770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>3294433487.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.116190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>329471118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.937912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  pred     value\n",
       "12789  3290333742.jpg      2     2  1.248505\n",
       "12795  3292343702.jpg      2     3  1.777464\n",
       "12801  3293012629.jpg      2     2  1.916770\n",
       "12810  3294433487.jpg      1     1  1.116190\n",
       "12813   329471118.jpg      1     1  1.937912"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_four\n",
    "placeholder = predict_image_list(four_fold[\"image_id\"], train_folder)\n",
    "four_fold[\"pred\"] = placeholder[0]\n",
    "four_fold[\"value\"] = placeholder[1]\n",
    "four_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4279/4279 [37:18<00:00,  1.91it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16944</th>\n",
       "      <td>4048377608.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.970032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16951</th>\n",
       "      <td>4049425598.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.849593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>4049743612.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.928237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16956</th>\n",
       "      <td>4050218395.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.957494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16958</th>\n",
       "      <td>4050718274.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.363522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  pred     value\n",
       "16944  4048377608.jpg      2     2  1.970032\n",
       "16951  4049425598.jpg      2     3  1.849593\n",
       "16954  4049743612.jpg      2     2  1.928237\n",
       "16956  4050218395.jpg      2     2  1.957494\n",
       "16958  4050718274.jpg      2     4  1.363522"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_five\n",
    "placeholder = predict_image_list(five_fold[\"image_id\"], train_folder)\n",
    "five_fold[\"pred\"] = placeholder[0]\n",
    "five_fold[\"value\"] = placeholder[1]\n",
    "five_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (one_fold[\"label\"] != one_fold[\"pred\"]) & (one_fold[\"value\"] >= threshold)\n",
    "one_list = one_fold[mask1].index.to_list()\n",
    "\n",
    "mask2 = (two_fold[\"label\"] != two_fold[\"pred\"]) & (two_fold[\"value\"] >= threshold)\n",
    "two_list = two_fold[mask2].index.to_list()\n",
    "\n",
    "mask3 = (three_fold[\"label\"] != three_fold[\"pred\"]) & (three_fold[\"value\"] >= threshold)\n",
    "three_list = three_fold[mask3].index.to_list()\n",
    "\n",
    "mask4 = (four_fold[\"label\"] != four_fold[\"pred\"]) & (four_fold[\"value\"] >= threshold)\n",
    "four_list = four_fold[mask4].index.to_list()\n",
    "\n",
    "mask5 = (five_fold[\"label\"] != five_fold[\"pred\"]) & (five_fold[\"value\"] >= threshold)\n",
    "five_list = five_fold[mask5].index.to_list()\n",
    "\n",
    "combined_list = list(np.unique(one_list + two_list + three_list + four_list + five_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    183\n",
       "4    117\n",
       "1     61\n",
       "3     58\n",
       "0     52\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_train.iloc[combined_list]\n",
    "temp[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Data To Be Removed: 2.20 %\n"
     ]
    }
   ],
   "source": [
    "pct = len(temp)/len(df_train)*100\n",
    "print(\"Percentage of Data To Be Removed: {:.2f}\".format(pct), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop these images & Re-fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.drop(combined_list, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 1\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 81s 445ms/step - loss: 1.3265 - accuracy: 0.5165 - val_loss: 0.9749 - val_accuracy: 0.6820\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.7753 - accuracy: 0.7377 - val_loss: 0.7747 - val_accuracy: 0.7511\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 43s 399ms/step - loss: 0.7147 - accuracy: 0.7456 - val_loss: 0.6625 - val_accuracy: 0.7836\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.6294 - accuracy: 0.8001 - val_loss: 0.5529 - val_accuracy: 0.8108\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.5702 - accuracy: 0.8132 - val_loss: 0.5133 - val_accuracy: 0.8254\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.5864 - accuracy: 0.8052 - val_loss: 0.4609 - val_accuracy: 0.8473\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 43s 402ms/step - loss: 0.5160 - accuracy: 0.8253 - val_loss: 0.4419 - val_accuracy: 0.8617\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.4785 - accuracy: 0.8456 - val_loss: 0.4101 - val_accuracy: 0.8638\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 42s 394ms/step - loss: 0.4804 - accuracy: 0.8310 - val_loss: 0.3915 - val_accuracy: 0.8741\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 0.4740 - accuracy: 0.8567 - val_loss: 0.3931 - val_accuracy: 0.8715\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 43s 404ms/step - loss: 0.5041 - accuracy: 0.8387 - val_loss: 0.3927 - val_accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.5017 - accuracy: 0.8369 - val_loss: 0.3934 - val_accuracy: 0.8731\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 41s 388ms/step - loss: 0.5067 - accuracy: 0.8254 - val_loss: 0.3943 - val_accuracy: 0.8736\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 41s 381ms/step - loss: 0.4337 - accuracy: 0.8661 - val_loss: 0.3945 - val_accuracy: 0.8712\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 41s 388ms/step - loss: 0.4636 - accuracy: 0.8493 - val_loss: 0.3943 - val_accuracy: 0.8712\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.4983 - accuracy: 0.8215 - val_loss: 0.3938 - val_accuracy: 0.8722\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.4395 - accuracy: 0.8563 - val_loss: 0.3947 - val_accuracy: 0.8722\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.4495 - accuracy: 0.8551 - val_loss: 0.3963 - val_accuracy: 0.8705\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 43s 404ms/step - loss: 0.4758 - accuracy: 0.8449 - val_loss: 0.3935 - val_accuracy: 0.8720\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 43s 402ms/step - loss: 0.4907 - accuracy: 0.8395 - val_loss: 0.3948 - val_accuracy: 0.8710\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 2\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 82s 464ms/step - loss: 1.2531 - accuracy: 0.5342 - val_loss: 0.8998 - val_accuracy: 0.6906\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.8257 - accuracy: 0.7213 - val_loss: 0.6509 - val_accuracy: 0.7799\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 43s 401ms/step - loss: 0.8054 - accuracy: 0.7277 - val_loss: 0.6597 - val_accuracy: 0.7959\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.6568 - accuracy: 0.7736 - val_loss: 0.5060 - val_accuracy: 0.8337\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.5311 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.8296\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.5363 - accuracy: 0.8166 - val_loss: 0.5174 - val_accuracy: 0.8201\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 43s 401ms/step - loss: 0.5195 - accuracy: 0.8156 - val_loss: 0.4577 - val_accuracy: 0.8485\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.4910 - accuracy: 0.8337 - val_loss: 0.4168 - val_accuracy: 0.8559\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.4993 - accuracy: 0.8188 - val_loss: 0.4154 - val_accuracy: 0.8542\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 42s 398ms/step - loss: 0.4632 - accuracy: 0.8401 - val_loss: 0.4148 - val_accuracy: 0.8540\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 42s 396ms/step - loss: 0.4736 - accuracy: 0.8411 - val_loss: 0.4149 - val_accuracy: 0.8542\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.4789 - accuracy: 0.8319 - val_loss: 0.4124 - val_accuracy: 0.8564\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 46s 434ms/step - loss: 0.6905 - accuracy: 0.7853 - val_loss: 0.4124 - val_accuracy: 0.8562\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 47s 437ms/step - loss: 0.4432 - accuracy: 0.8582 - val_loss: 0.4142 - val_accuracy: 0.8535\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.4867 - accuracy: 0.8292 - val_loss: 0.4137 - val_accuracy: 0.8545\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 45s 421ms/step - loss: 0.5033 - accuracy: 0.8242 - val_loss: 0.4118 - val_accuracy: 0.8554\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 44s 417ms/step - loss: 0.4510 - accuracy: 0.8391 - val_loss: 0.4132 - val_accuracy: 0.8552\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 44s 414ms/step - loss: 0.4542 - accuracy: 0.8467 - val_loss: 0.4157 - val_accuracy: 0.8542\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 44s 410ms/step - loss: 0.4665 - accuracy: 0.8271 - val_loss: 0.4127 - val_accuracy: 0.8545\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.4869 - accuracy: 0.8289 - val_loss: 0.4148 - val_accuracy: 0.8535\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 3\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 81s 443ms/step - loss: 1.3192 - accuracy: 0.4790 - val_loss: 0.9391 - val_accuracy: 0.6593\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 43s 401ms/step - loss: 0.7951 - accuracy: 0.6890 - val_loss: 0.7426 - val_accuracy: 0.7216\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 43s 408ms/step - loss: 0.7302 - accuracy: 0.7329 - val_loss: 0.5332 - val_accuracy: 0.8234\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 46s 431ms/step - loss: 0.6468 - accuracy: 0.7767 - val_loss: 0.5208 - val_accuracy: 0.8447\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.6214 - accuracy: 0.7929 - val_loss: 0.7719 - val_accuracy: 0.8022\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 45s 420ms/step - loss: 0.5779 - accuracy: 0.8119 - val_loss: 0.4948 - val_accuracy: 0.8440\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.5048 - accuracy: 0.8274 - val_loss: 0.3966 - val_accuracy: 0.8757\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 46s 427ms/step - loss: 0.4614 - accuracy: 0.8483 - val_loss: 0.3673 - val_accuracy: 0.8908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "107/107 [==============================] - 45s 427ms/step - loss: 0.4595 - accuracy: 0.8330 - val_loss: 0.3703 - val_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 42s 394ms/step - loss: 0.4714 - accuracy: 0.8380 - val_loss: 0.3683 - val_accuracy: 0.8884\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 42s 394ms/step - loss: 0.4853 - accuracy: 0.8412 - val_loss: 0.3658 - val_accuracy: 0.8882\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.4494 - accuracy: 0.8463 - val_loss: 0.3645 - val_accuracy: 0.8884\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 42s 392ms/step - loss: 0.4683 - accuracy: 0.8480 - val_loss: 0.3635 - val_accuracy: 0.8882\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 41s 389ms/step - loss: 0.4435 - accuracy: 0.8540 - val_loss: 0.3651 - val_accuracy: 0.8872\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.4858 - accuracy: 0.8310 - val_loss: 0.3661 - val_accuracy: 0.8875\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 41s 384ms/step - loss: 0.5014 - accuracy: 0.8272 - val_loss: 0.3652 - val_accuracy: 0.8884\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 41s 389ms/step - loss: 0.4227 - accuracy: 0.8655 - val_loss: 0.3669 - val_accuracy: 0.8863\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 42s 394ms/step - loss: 0.4559 - accuracy: 0.8523 - val_loss: 0.3695 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.4127 - accuracy: 0.8675 - val_loss: 0.3651 - val_accuracy: 0.8870\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 45s 418ms/step - loss: 0.4821 - accuracy: 0.8415 - val_loss: 0.3666 - val_accuracy: 0.8867\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 4\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 82s 448ms/step - loss: 1.3689 - accuracy: 0.3990 - val_loss: 1.0775 - val_accuracy: 0.6327\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 43s 398ms/step - loss: 0.8696 - accuracy: 0.6512 - val_loss: 0.7270 - val_accuracy: 0.7591\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.7682 - accuracy: 0.7136 - val_loss: 0.6107 - val_accuracy: 0.7988\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 42s 397ms/step - loss: 0.7086 - accuracy: 0.7437 - val_loss: 0.6604 - val_accuracy: 0.8033\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 43s 403ms/step - loss: 0.6217 - accuracy: 0.8081 - val_loss: 0.5067 - val_accuracy: 0.8399\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 45s 427ms/step - loss: 0.5830 - accuracy: 0.8064 - val_loss: 0.5182 - val_accuracy: 0.8366\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 45s 424ms/step - loss: 0.5396 - accuracy: 0.8291 - val_loss: 0.4165 - val_accuracy: 0.8767\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.5650 - accuracy: 0.8252 - val_loss: 0.4298 - val_accuracy: 0.8755\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 46s 434ms/step - loss: 0.4850 - accuracy: 0.8375 - val_loss: 0.4081 - val_accuracy: 0.8808\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 48s 446ms/step - loss: 0.4896 - accuracy: 0.8404 - val_loss: 0.4074 - val_accuracy: 0.8796\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 46s 428ms/step - loss: 0.4976 - accuracy: 0.8501 - val_loss: 0.4068 - val_accuracy: 0.8789\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 41s 384ms/step - loss: 0.4521 - accuracy: 0.8536 - val_loss: 0.4053 - val_accuracy: 0.8793\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 41s 386ms/step - loss: 0.4903 - accuracy: 0.8413 - val_loss: 0.4019 - val_accuracy: 0.8805\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 40s 378ms/step - loss: 0.4780 - accuracy: 0.8505 - val_loss: 0.4039 - val_accuracy: 0.8800\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 40s 371ms/step - loss: 0.4632 - accuracy: 0.8411 - val_loss: 0.4068 - val_accuracy: 0.8805\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 40s 380ms/step - loss: 0.4704 - accuracy: 0.8402 - val_loss: 0.4054 - val_accuracy: 0.8800\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 39s 368ms/step - loss: 0.4998 - accuracy: 0.8607 - val_loss: 0.4074 - val_accuracy: 0.8791\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 0.6120 - accuracy: 0.8114 - val_loss: 0.4103 - val_accuracy: 0.8784\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 38s 356ms/step - loss: 0.4673 - accuracy: 0.8429 - val_loss: 0.4062 - val_accuracy: 0.8784\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.4991 - accuracy: 0.8318 - val_loss: 0.4098 - val_accuracy: 0.8777\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Training fold no.: 5\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 73s 385ms/step - loss: 1.1880 - accuracy: 0.5976 - val_loss: 1.0735 - val_accuracy: 0.6569\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 37s 343ms/step - loss: 0.8457 - accuracy: 0.6704 - val_loss: 0.8696 - val_accuracy: 0.6669\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 37s 346ms/step - loss: 0.7847 - accuracy: 0.7261 - val_loss: 0.5835 - val_accuracy: 0.8041\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 37s 352ms/step - loss: 0.7280 - accuracy: 0.7539 - val_loss: 0.6142 - val_accuracy: 0.8076\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 37s 346ms/step - loss: 0.6407 - accuracy: 0.7806 - val_loss: 0.5290 - val_accuracy: 0.8389\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 37s 344ms/step - loss: 0.5716 - accuracy: 0.8096 - val_loss: 0.4532 - val_accuracy: 0.8492\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 36s 342ms/step - loss: 0.5617 - accuracy: 0.8145 - val_loss: 0.3967 - val_accuracy: 0.8779\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 37s 346ms/step - loss: 0.5021 - accuracy: 0.8402 - val_loss: 0.3999 - val_accuracy: 0.8722\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 38s 352ms/step - loss: 0.4876 - accuracy: 0.8334 - val_loss: 0.3872 - val_accuracy: 0.8781\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 37s 343ms/step - loss: 0.4518 - accuracy: 0.8620 - val_loss: 0.3839 - val_accuracy: 0.8774\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.4837 - accuracy: 0.8357 - val_loss: 0.3820 - val_accuracy: 0.8789\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 36s 342ms/step - loss: 0.4669 - accuracy: 0.8551 - val_loss: 0.3780 - val_accuracy: 0.8820\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 37s 342ms/step - loss: 0.4876 - accuracy: 0.8285 - val_loss: 0.3764 - val_accuracy: 0.8822\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 36s 336ms/step - loss: 0.4722 - accuracy: 0.8573 - val_loss: 0.3784 - val_accuracy: 0.8815\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 36s 341ms/step - loss: 0.4705 - accuracy: 0.8368 - val_loss: 0.3800 - val_accuracy: 0.8805\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 37s 345ms/step - loss: 0.4786 - accuracy: 0.8541 - val_loss: 0.3789 - val_accuracy: 0.8827\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 36s 342ms/step - loss: 0.4502 - accuracy: 0.8624 - val_loss: 0.3793 - val_accuracy: 0.8803\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 37s 345ms/step - loss: 0.4901 - accuracy: 0.8351 - val_loss: 0.3758 - val_accuracy: 0.8824\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 37s 345ms/step - loss: 0.4862 - accuracy: 0.8369 - val_loss: 0.3777 - val_accuracy: 0.8812\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 37s 347ms/step - loss: 0.4401 - accuracy: 0.8645 - val_loss: 0.3801 - val_accuracy: 0.8805\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "fold_number = 0\n",
    "n_splits = 5\n",
    "oof_accuracy = []\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "for train_index, val_index in skf.split(df[\"image_id\"], df[\"label\"]):\n",
    "    # clearing memory\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # data split\n",
    "    train_set = df.loc[train_index]\n",
    "    val_set = df.loc[val_index]\n",
    "    \n",
    "    train_data, val_data_ = train_val_split(train_set, val_set)\n",
    "    \n",
    "    train_alb = augment_train_data(train_data)\n",
    "    val_alb = augment_val_data(val_data_)\n",
    "    \n",
    "    #train_final, val_final = optimize_data(train_alb, val_alb)\n",
    "    \n",
    "    train_alb_mod = train_alb.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    train_final = train_alb_mod.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    val_alb_mod = val_alb.map(onehot, num_parallel_calls=AUTOTUNE)\n",
    "    val_final = val_alb_mod.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    \n",
    "    model = create_model()\n",
    "    print(\"Training fold no.: \" + str(fold_number+1))\n",
    "\n",
    "    model_name = \"denoised effnetb4 \"\n",
    "    fold_name = \"fold.h5\"\n",
    "    filepath = model_name + str(fold_number+1) + fold_name\n",
    "    callbacks = [ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True)]\n",
    "\n",
    "    history = model.fit(train_final, steps_per_epoch=total_steps, epochs=epochs, validation_data=val_final, callbacks=callbacks)\n",
    "    oof_accuracy.append(max(history.history[\"val_accuracy\"]))\n",
    "    fold_number += 1\n",
    "    if fold_number == n_splits:\n",
    "        print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Out-Of-Fold Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Out-Of-Fold Accuracy: {:.2f}\".format(np.mean(oof_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
